{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Malaria_Diagnosis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qfja9tMaB1ZH"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFcRTOdwH5hq"
      },
      "source": [
        "# **Data** üìç\n",
        "\n",
        "Within this section we will be importing the data, opening and reading it, and organizing the data into training and validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxHWf1NoprCa",
        "collapsed": true
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://ceb.nlm.nih.gov/proj/malaria/cell_images.zip \\\n",
        "    -O /tmp/cell_images.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLy3pthUS0D2"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/cell_images.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnyplDwYCDI9"
      },
      "source": [
        "os.mkdir(\"/tmp/cell_images/train\")\n",
        "os.mkdir(\"/tmp/cell_images/valid\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqFWQiDRCKeT"
      },
      "source": [
        "os.mkdir(\"/tmp/cell_images/train/Parasitized\")\n",
        "os.mkdir(\"/tmp/cell_images/train/Uninfected\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nIxlk1ACUc7"
      },
      "source": [
        "import random\n",
        "import shutil\n",
        "source1 = '/tmp/cell_images/Parasitized'\n",
        "dest1 = '/tmp/cell_images/train/Parasitized'\n",
        "files = os.listdir(source1)\n",
        "for fileName in random.sample(files, min(len(files), 10334)):\n",
        "    path = os.path.join(source1, fileName)\n",
        "    shutil.move(path, dest1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMRJoUBbLySt"
      },
      "source": [
        "source2 = '/tmp/cell_images/Uninfected'\n",
        "dest2 = '/tmp/cell_images/train/Uninfected'\n",
        "files = os.listdir(source2)\n",
        "for fileName in random.sample(files, min(len(files), 10334)):\n",
        "    path = os.path.join(source2, fileName)\n",
        "    shutil.move(path, dest2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI_98uuQMMnJ"
      },
      "source": [
        "parasite = '/tmp/cell_images/Parasitized'\n",
        "uninfec = '/tmp/cell_images/Uninfected'\n",
        "valid = '/tmp/cell_images/valid'\n",
        "shutil.move(parasite,valid)\n",
        "shutil.move(uninfec, valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLZKVtE0dSfk"
      },
      "source": [
        "base_dir = '/tmp/cell_images'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'valid')\n",
        "train_Parasitized_dir = os.path.join(train_dir, 'Parasitized')\n",
        "train_Uninfected_dir = os.path.join(train_dir, 'Uninfected')\n",
        "validation_Parasitized_dir = os.path.join(validation_dir, 'Parasitized')\n",
        "validation_Uninfected_dir = os.path.join(validation_dir, 'Uninfected')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PIP1rkmeAYS"
      },
      "source": [
        "train_Parasitized_fnames = os.listdir(train_Parasitized_dir)\n",
        "print(train_Parasitized_fnames[:10])\n",
        "\n",
        "train_Uninfected_fnames = os.listdir(train_Uninfected_dir)\n",
        "train_Uninfected_fnames.sort()\n",
        "print(train_Uninfected_fnames[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4XHh2xSfgie"
      },
      "source": [
        "print('total training Parasitized images:', len(os.listdir(train_Parasitized_dir)))\n",
        "print('total training Uninfected images:', len(os.listdir(train_Uninfected_dir)))\n",
        "print('total validation Parasitized images:', len(os.listdir(validation_Parasitized_dir)))\n",
        "print('total validation Uninfected images:', len(os.listdir(validation_Uninfected_dir)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2_Q0-_5UAv-"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "\n",
        "# Index for iterating over images\n",
        "pic_index = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpr8GxjOU8in"
      },
      "source": [
        "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols * 4, nrows * 4)\n",
        "\n",
        "pic_index += 8\n",
        "next_Parasitized_pix = [os.path.join(train_Parasitized_dir, fname) \n",
        "                for fname in train_Parasitized_fnames[pic_index-8:pic_index]]\n",
        "next_Uninfected_pix = [os.path.join(train_Uninfected_dir, fname) \n",
        "                for fname in train_Uninfected_fnames[pic_index-8:pic_index]]\n",
        "\n",
        "for i, img_path in enumerate(next_Parasitized_pix+next_Uninfected_pix):\n",
        "  # Set up subplot; subplot indices start at 1\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('Off') # Don't show axes (or gridlines)\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRjO0v9UKrGv"
      },
      "source": [
        "# **Training the Model** üèãÔ∏è\n",
        "\n",
        "In this section we will be importing the training algorithm and training our model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYVLSfbsbf9K"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugysGIPxnaYo"
      },
      "source": [
        "img_input = layers.Input(shape=(150, 150, 3))\n",
        "\n",
        "x = layers.Conv2D(16, 3, activation='relu')(img_input)\n",
        "x = layers.MaxPooling2D(2)(x)\n",
        "\n",
        "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
        "x = layers.MaxPooling2D(2)(x)\n",
        "\n",
        "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
        "x = layers.MaxPooling2D(2)(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v88_ZTAslvR"
      },
      "source": [
        "x = layers.Flatten()(x)\n",
        "\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "\n",
        "output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(img_input, output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZKj8392nbgP"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DHWhFP_uhq3"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.001),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClebU9NJg99G"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(150, 150), \n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=50,\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZoCuyHgXd5i"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "train_dir,  # This is the source directory for training images\n",
        "target_size=(150, 150),  # All images will be resized to 150x150\n",
        "\n",
        "batch_size=50,\n",
        "class_mode='binary')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "validation_dir,\n",
        "target_size=(150, 150),\n",
        "batch_size=50,\n",
        "class_mode='binary')\n",
        "\n",
        "history = model.fit_generator(\n",
        "train_generator,\n",
        "steps_per_epoch=25,\n",
        "epochs=10,\n",
        "validation_data=validation_generator,\n",
        "validation_steps=25,\n",
        "verbose=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfXYi28sODQy"
      },
      "source": [
        "# Results üìà\n",
        "\n",
        "In this section we produce graphs and illustrations that demonstrate the capabilities of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p07OL14-Eikg"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, val_acc)\n",
        "plt.title('Accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, val_loss)\n",
        "plt.title('Loss')\n",
        "print(val_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5tES8rXFjux"
      },
      "source": [
        "import random\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "# Let's define a new Model that will take an image as input, and will output\n",
        "# intermediate representations for all layers in the previous model after\n",
        "# the first.\n",
        "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
        "visualization_model = Model(img_input, successive_outputs)\n",
        "\n",
        "# Let's prepare a random input image of a parasitized cell or uninfected cell from the training set.\n",
        "Parasitized_img_files = [os.path.join(train_Parasitized_dir, f) for f in train_Parasitized_fnames]\n",
        "Uninfected_img_files = [os.path.join(train_Uninfected_dir, f) for f in train_Uninfected_fnames]\n",
        "img_path = random.choice(Parasitized_img_files + Uninfected_img_files)\n",
        "\n",
        "img = load_img(img_path, target_size=(150, 150))  # this is a PIL image\n",
        "x = img_to_array(img)  # Numpy array with shape (150, 150, 3)\n",
        "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
        "\n",
        "# Rescale by 1/255\n",
        "x /= 255\n",
        "\n",
        "# Let's run our image through our network, thus obtaining all\n",
        "# intermediate representations for this image.\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "# These are the names of the layers, so can have them as part of our plot\n",
        "layer_names = [layer.name for layer in model.layers]\n",
        "\n",
        "# Now let's display our representations\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "  if len(feature_map.shape) == 4:\n",
        "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
        "    n_features = feature_map.shape[-1]  # number of features in feature map\n",
        "    # The feature map has shape (1, size, size, n_features)\n",
        "    size = feature_map.shape[1]\n",
        "    # We will tile our images in this matrix\n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "    for i in range(n_features):\n",
        "      # Postprocess the feature to make it visually palatable\n",
        "      x = feature_map[0, :, :, i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std()\n",
        "      x *= 64\n",
        "      x += 128\n",
        "      x = np.clip(x, 0, 255).astype('uint8')\n",
        "      # We'll tile each filter into this big horizontal grid\n",
        "      display_grid[:, i * size : (i + 1) * size] = x\n",
        "    # Display the grid\n",
        "    scale = 20. / n_features\n",
        "    plt.figure(figsize=(scale * n_features, scale))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oj0gTIy4k60"
      },
      "source": [
        "# Retrieve a list of accuracy results on training and validation data\n",
        "# sets for each training epoch\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "# Retrieve a list of list results on training and validation data\n",
        "# sets for each training epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Get number of epochs\n",
        "epochs = range(len(acc))\n",
        "\n",
        "# Plot training and validation accuracy per epoch\n",
        "plt.plot(epochs, val_acc)\n",
        "plt.title('Accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Plot training and validation loss per epoch\n",
        "plt.plot(epochs, val_loss)\n",
        "plt.title('Loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9wUH3CIFRI_"
      },
      "source": [
        "model.save('keras.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}